{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import plotly\n",
    "plotly.offline.init_notebook_mode()\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "data = load_boston()\n",
    "df = pd.concat([pd.DataFrame(data['data'], columns = data['feature_names']), \n",
    "                pd.DataFrame(data['target'], columns=['MEDV'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "import plotly.express as px\n",
    "X = df.drop(['MEDV'], axis=1)\n",
    "y = df['MEDV']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Code adopted from https://machinelearningmastery.com/feature-selection-for-regression-data/\n",
    "###\n",
    "fs = SelectKBest(score_func=mutual_info_regression, k='all')\n",
    "# learn relationship from training data\n",
    "fs.fit(X_train, y_train)\n",
    "# transform train input data\n",
    "X_train_fs = fs.transform(X_train)\n",
    "# transform test input data\n",
    "X_test_fs = fs.transform(X_test)\n",
    "\n",
    "_dict_features={'Features':[], 'Score':[]}\n",
    "\n",
    "for score_feature, column in zip(fs.scores_, df.columns):\n",
    "    _dict_features['Features'].append(column)\n",
    "    _dict_features['Score'].append(score_feature)\n",
    "    \n",
    "_df=pd.DataFrame(_dict_features)\n",
    "\n",
    "# plot the scores\n",
    "fig = px.bar(_df, x='Features', y='Score', title=\"Visualization of the dependence of the target variable on features\")\n",
    "fig.update_layout(height=500, width=950)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessors\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "#Algorithms\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "#Metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score \n",
    "#Additional\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for getting a best model by MAE\n",
    "def evaluating_scores(pipeline, X, y, scoring_mae='neg_mean_absolute_error', scoring_r2='r2', cv=5):\n",
    "    #Get values from Preprocessors and Regressors\n",
    "    preprocessors_names=list(pipeline.named_steps.values())[0]\n",
    "    regressors_names=list(pipeline.named_steps.values())[1]\n",
    "    #Get MAE on Cross Validation\n",
    "    score_mae=-cross_val_score(pipeline, X, y, scoring=scoring_mae, cv=cv).mean()\n",
    "    #Returning a dict to transform in DataFrame\n",
    "    return dict(preprocessor=preprocessors_names, regressor=regressors_names, score_mae=score_mae)\n",
    "\n",
    "\n",
    "def find_optimum(X, y):\n",
    "    #Set Preprocessors\n",
    "    preprocessors=[MinMaxScaler(), \n",
    "                   StandardScaler(), \n",
    "                   RobustScaler()]\n",
    "    #Set Algorithms\n",
    "    regressors=[RandomForestRegressor(random_state=42),\n",
    "                KNeighborsRegressor(),\n",
    "                LinearRegression(),\n",
    "                XGBRegressor(random_state=42)] \n",
    "    \n",
    "    #A list for pipelines\n",
    "    _list_est=[]\n",
    "    \n",
    "    #Get all possible pipelines using Brute-Force Search\n",
    "    for preprocessor in preprocessors:\n",
    "        for regressor in regressors:\n",
    "            _list_est.append(make_pipeline(preprocessor, regressor))\n",
    "            \n",
    "    #Computing scores for all pipelines using all computing resources\n",
    "    computed=Parallel(n_jobs=-1)(delayed(evaluating_scores)(pipeline, X, y) for pipeline in _list_est)\n",
    "    \n",
    "    #Returning a transformed DataFrame from a dict with evaluated scores\n",
    "    return round(pd.DataFrame(computed).sort_values('score_mae').reset_index(drop=True), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=find_optimum(X, y)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
